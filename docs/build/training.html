

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Training Custom Object Detector &mdash; TensorFlow 2 Object Detection API tutorial  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Examples" href="auto_examples/index.html" />
    <link rel="prev" title="Installation" href="install.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> TensorFlow 2 Object Detection API tutorial
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training Custom Object Detector</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preparing-the-workspace">Preparing the Workspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="#preparing-the-dataset">Preparing the Dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#annotate-images">Annotate Images</a></li>
<li class="toctree-l3"><a class="reference internal" href="#partition-the-dataset">Partition the Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-label-map">Create Label Map</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-tensorflow-records">Create TensorFlow Records</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#convert-xml-to-record">Convert <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> to <code class="docutils literal notranslate"><span class="pre">*.record</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#configuring-a-training-job">Configuring a Training Job</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#download-pre-trained-model">Download Pre-Trained Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configure-the-training-pipeline">Configure the Training Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-the-model">Training the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#evaluating-the-model-optional">Evaluating the Model (Optional)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#monitor-training-job-progress-using-tensorboard">Monitor Training Job Progress using TensorBoard</a></li>
<li class="toctree-l2"><a class="reference internal" href="#exporting-a-trained-inference-graph">Exporting a Trained Inference Graph</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="issues.html">Common issues</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TensorFlow 2 Object Detection API tutorial</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Training Custom Object Detector</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/training.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="training-custom-object-detector">
<h1>Training Custom Object Detector<a class="headerlink" href="#training-custom-object-detector" title="Permalink to this headline">¶</a></h1>
<p>So, up to now you should have done the following:</p>
<ul class="simple">
<li><p>Installed TensorFlow (See <a class="reference internal" href="install.html#tf-install"><span class="std std-ref">TensorFlow Installation</span></a>)</p></li>
<li><p>Installed TensorFlow Object Detection API (See <a class="reference internal" href="install.html#tf-models-install"><span class="std std-ref">TensorFlow Object Detection API Installation</span></a>)</p></li>
<li><p>Installed labelImg (See <a class="reference internal" href="install.html#labelimg-install"><span class="std std-ref">LabelImg Installation</span></a>)</p></li>
</ul>
<p>Now that we have done all the above, we can start doing some cool stuff. Here we will see how you can train your own object detector, and since it is not as simple as it sounds, we will have a look at:</p>
<ol class="arabic simple">
<li><p>How to organise your workspace/training files</p></li>
<li><p>How to prepare/annotate image datasets</p></li>
<li><p>How to generate tf records from such datasets</p></li>
<li><p>How to configure a simple training pipeline</p></li>
<li><p>How to train a model and monitor it’s progress</p></li>
<li><p>How to export the resulting model and use it to detect objects.</p></li>
</ol>
<div class="section" id="preparing-the-workspace">
<h2>Preparing the Workspace<a class="headerlink" href="#preparing-the-workspace" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p>If you have followed the tutorial, you should by now have a folder <code class="docutils literal notranslate"><span class="pre">Tensorflow</span></code>, placed under <code class="docutils literal notranslate"><span class="pre">&lt;PATH_TO_TF&gt;</span></code> (e.g. <code class="docutils literal notranslate"><span class="pre">C:/Users/sglvladi/Documents</span></code>), with the following directory tree:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TensorFlow/
├─ addons/ <span class="o">(</span>Optional<span class="o">)</span>
│  └─ labelImg/
└─ models/
   ├─ community/
   ├─ official/
   ├─ orbit/
   ├─ research/
   └─ ...
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Now create a new folder under <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code>  and call it <code class="docutils literal notranslate"><span class="pre">workspace</span></code>. It is within the <code class="docutils literal notranslate"><span class="pre">workspace</span></code> that we will store all our training set-ups. Now let’s go under workspace and create another folder named <code class="docutils literal notranslate"><span class="pre">training_demo</span></code>. Now our directory structure should be as so:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TensorFlow/
├─ addons/ <span class="o">(</span>Optional<span class="o">)</span>
│  └─ labelImg/
├─ models/
│  ├─ community/
│  ├─ official/
│  ├─ orbit/
│  ├─ research/
│  └─ ...
└─ workspace/
   └─ training_demo/
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder shall be our <cite>training folder</cite>, which will contain all files related to our model training. It is advisable to create a separate training folder each time we wish to train a different model. The typical structure for training folders is shown below.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>training_demo/
├─ annotations/
├─ images/
│  ├─ test/
│  └─ train/
├─ models/
├─ pre-trained-models/
└─ README.md
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
<p>Here’s an explanation for each of the folders/filer shown in the above tree:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">annotations</span></code>: This folder will be used to store all <code class="docutils literal notranslate"><span class="pre">*.csv</span></code> files and the respective TensorFlow <code class="docutils literal notranslate"><span class="pre">*.record</span></code> files, which contain the list of annotations for our dataset images.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">images</span></code>: This folder contains a copy of all the images in our dataset, as well as the respective <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files produced for each one, once <code class="docutils literal notranslate"><span class="pre">labelImg</span></code> is used to annotate objects.</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">images/train</span></code>: This folder contains a copy of all images, and the respective <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files, which will be used to train our model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">images/test</span></code>: This folder contains a copy of all images, and the respective <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files, which will be used to test our model.</p></li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">models</span></code>: This folder will contain a sub-folder for each of training job. Each subfolder will contain the training pipeline configuration file <code class="docutils literal notranslate"><span class="pre">*.config</span></code>, as well as all files generated during the training and evaluation of our model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pre-trained-models</span></code>: This folder will contain the downloaded pre-trained models, which shall be used as a starting checkpoint for our training jobs.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">README.md</span></code>: This is an optional file which provides some general information regarding the training conditions of our model. It is not used by TensorFlow in any way, but it generally helps when you have a few training folders and/or you are revisiting a trained model after some time.</p></li>
</ul>
<p>If you do not understand most of the things mentioned above, no need to worry, as we’ll see how all the files are generated further down.</p>
</div>
<div class="section" id="preparing-the-dataset">
<h2>Preparing the Dataset<a class="headerlink" href="#preparing-the-dataset" title="Permalink to this headline">¶</a></h2>
<div class="section" id="annotate-images">
<h3>Annotate Images<a class="headerlink" href="#annotate-images" title="Permalink to this headline">¶</a></h3>
<p>To annotate images we will be using the <a class="reference external" href="https://github.com/tzutalin/labelImg">labelImg</a> package. If you haven’t installed the package yet, then have a look at <a class="reference internal" href="install.html#labelimg-install"><span class="std std-ref">LabelImg Installation</span></a>.</p>
<ul>
<li><p>Once you have collected all the images to be used to test your model (ideally more than 100 per class), place them inside the folder <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code>.</p></li>
<li><p>Open a new <cite>Anaconda/Command Prompt</cite> window and <code class="docutils literal notranslate"><span class="pre">cd</span></code> into <code class="docutils literal notranslate"><span class="pre">Tensorflow/addons/labelImg</span></code>.</p></li>
<li><p>If (as suggested in <a class="reference internal" href="install.html#labelimg-install"><span class="std std-ref">LabelImg Installation</span></a>) you created a separate Conda environment for <code class="docutils literal notranslate"><span class="pre">labelImg</span></code> then go ahead and activate it by running:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>activate labelImg
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Next go ahead and start <code class="docutils literal notranslate"><span class="pre">labelImg</span></code>, pointing it to your <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code> folder.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python labelImg.py ../../workspace/training_demo/images
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>A File Explorer Dialog windows should open, which points to the <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code> folder.</p></li>
<li><p>Press the “Select Folder” button, to start annotating your images.</p></li>
</ul>
<p>Once open, you should see a window similar to the one below:</p>
<a class="reference internal image-reference" href="_images/labelImg.JPG"><img alt="alternate text" class="align-center" src="_images/labelImg.JPG" style="width: 90%;" /></a>
<p>I won’t be covering a tutorial on how to use <code class="docutils literal notranslate"><span class="pre">labelImg</span></code>, but you can have a look at <a class="reference external" href="https://github.com/tzutalin/labelImg#usage">labelImg’s repo</a> for more details. A nice Youtube video demonstrating how to use <code class="docutils literal notranslate"><span class="pre">labelImg</span></code> is also available <a class="reference external" href="https://youtu.be/K_mFnvzyLvc?t=9m13s">here</a>. What is important is that once you annotate all your images, a set of new <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files, one for each image, should be generated inside your <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code> folder.</p>
</div>
<div class="section" id="partition-the-dataset">
<span id="image-partitioning-sec"></span><h3>Partition the Dataset<a class="headerlink" href="#partition-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>Once you have finished annotating your image dataset, it is a general convention to use only part of it for training, and the rest is used for evaluation purposes (e.g. as discussed in <a class="reference internal" href="#evaluation-sec"><span class="std std-ref">Evaluating the Model (Optional)</span></a>).</p>
<p>Typically, the ratio is 90%/10%, i.e. 90% of the images are used for training and the rest 10% is maintained for testing, but you can chose whatever ratio suits your needs.</p>
<p>Once you have decided how you will be splitting your dataset, copy all training images, together with their corresponding <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files, and place them inside the <code class="docutils literal notranslate"><span class="pre">training_demo/images/train</span></code> folder. Similarly, copy all testing images, with their <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files, and paste them inside <code class="docutils literal notranslate"><span class="pre">training_demo/images/test</span></code>.</p>
<p>For lazy people like myself, who cannot be bothered to do the above, I have put tugether a simple script that automates the above process:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; usage: partition_dataset.py [-h] [-i IMAGEDIR] [-o OUTPUTDIR] [-r RATIO] [-x]</span>

<span class="sd">Partition dataset of images into training and testing sets</span>

<span class="sd">optional arguments:</span>
<span class="sd">  -h, --help            show this help message and exit</span>
<span class="sd">  -i IMAGEDIR, --imageDir IMAGEDIR</span>
<span class="sd">                        Path to the folder where the image dataset is stored. If not specified, the CWD will be used.</span>
<span class="sd">  -o OUTPUTDIR, --outputDir OUTPUTDIR</span>
<span class="sd">                        Path to the output folder where the train and test dirs should be created. Defaults to the same directory as IMAGEDIR.</span>
<span class="sd">  -r RATIO, --ratio RATIO</span>
<span class="sd">                        The ratio of the number of test images over the total number of images. The default is 0.1.</span>
<span class="sd">  -x, --xml             Set this flag if you want the xml annotation files to be processed and copied over.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="k">import</span> <span class="n">copyfile</span>
<span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">random</span>


<span class="k">def</span> <span class="nf">iterate_dir</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">dest</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">copy_xml</span><span class="p">):</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">source</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;/&#39;</span><span class="p">)</span>
    <span class="n">dest</span> <span class="o">=</span> <span class="n">dest</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;/&#39;</span><span class="p">)</span>
    <span class="n">train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">test_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dest</span><span class="p">,</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">train_dir</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">train_dir</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">test_dir</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">test_dir</span><span class="p">)</span>

    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
              <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;([a-zA-Z0-9\s_</span><span class="se">\\</span><span class="s1">.\-\(\):])+(.jpg|.jpeg|.png)$&#39;</span><span class="p">,</span> <span class="n">f</span><span class="p">)]</span>

    <span class="n">num_images</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">num_test_images</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">ratio</span><span class="o">*</span><span class="n">num_images</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_test_images</span><span class="p">):</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">copyfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">filename</span><span class="p">),</span>
                 <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">copy_xml</span><span class="p">:</span>
            <span class="n">xml_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;.xml&#39;</span>
            <span class="n">copyfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">xml_filename</span><span class="p">),</span>
                     <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span><span class="n">xml_filename</span><span class="p">))</span>
        <span class="n">images</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">filename</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
        <span class="n">copyfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">filename</span><span class="p">),</span>
                 <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">copy_xml</span><span class="p">:</span>
            <span class="n">xml_filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">filename</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="s1">&#39;.xml&#39;</span>
            <span class="n">copyfile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">xml_filename</span><span class="p">),</span>
                     <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span> <span class="n">xml_filename</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="c1"># Initiate argument parser</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">&quot;Partition dataset of images into training and testing sets&quot;</span><span class="p">,</span>
                                     <span class="n">formatter_class</span><span class="o">=</span><span class="n">argparse</span><span class="o">.</span><span class="n">RawTextHelpFormatter</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s1">&#39;-i&#39;</span><span class="p">,</span> <span class="s1">&#39;--imageDir&#39;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Path to the folder where the image dataset is stored. If not specified, the CWD will be used.&#39;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s1">&#39;-o&#39;</span><span class="p">,</span> <span class="s1">&#39;--outputDir&#39;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Path to the output folder where the train and test dirs should be created. &#39;</span>
             <span class="s1">&#39;Defaults to the same directory as IMAGEDIR.&#39;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="s1">&#39;--ratio&#39;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;The ratio of the number of test images over the total number of images. The default is 0.1.&#39;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s1">&#39;-x&#39;</span><span class="p">,</span> <span class="s1">&#39;--xml&#39;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s1">&#39;Set this flag if you want the xml annotation files to be processed and copied over.&#39;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s1">&#39;store_true&#39;</span>
    <span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">outputDir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">args</span><span class="o">.</span><span class="n">outputDir</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">imageDir</span>

    <span class="c1"># Now we are ready to start the iteration</span>
    <span class="n">iterate_dir</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">imageDir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">outputDir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">ratio</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">xml</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<ul>
<li><p>Click <a class="reference download internal" download="" href="_downloads/d0e545609c5f7f49f39abc7b6a38cec3/partition_dataset.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a> to download the above script and save it inside <code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts/preprocessing</span></code>.</p></li>
<li><p>Then,  <code class="docutils literal notranslate"><span class="pre">cd</span></code> into <code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts/preprocessing</span></code> and run:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">partition_dataset</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">x</span> <span class="o">-</span><span class="n">i</span> <span class="p">[</span><span class="n">PATH_TO_IMAGES_FOLDER</span><span class="p">]</span> <span class="o">-</span><span class="n">r</span> <span class="mf">0.1</span>

<span class="c1"># For example</span>
<span class="c1"># python partition_dataset.py -x -i C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images -r 0.1</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<p>Once the script has finished, two new folders should have been created under <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code>,
namely <code class="docutils literal notranslate"><span class="pre">training_demo/images/train</span></code> and <code class="docutils literal notranslate"><span class="pre">training_demo/images/test</span></code>, containing 90% and 10% of
the images (and <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files), respectively. To avoid loss of any files, the script will not
delete the images under <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code>. Once you have checked that your images have been
safely copied over, you can delete the images under <code class="docutils literal notranslate"><span class="pre">training_demo/images</span></code> manually.</p>
</div>
<div class="section" id="create-label-map">
<h3>Create Label Map<a class="headerlink" href="#create-label-map" title="Permalink to this headline">¶</a></h3>
<p>TensorFlow requires a label map, which namely maps each of the used labels to an integer values. This label map is used both by the training and detection processes.</p>
<p>Below we show an example label map (e.g <code class="docutils literal notranslate"><span class="pre">label_map.pbtxt</span></code>), assuming that our dataset containes 2 labels, <code class="docutils literal notranslate"><span class="pre">dogs</span></code> and <code class="docutils literal notranslate"><span class="pre">cats</span></code>:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span>item {
    id: 1
    name: &#39;cat&#39;
}

item {
    id: 2
    name: &#39;dog&#39;
}
</pre></div>
</div>
<p>Label map files have the extention <code class="docutils literal notranslate"><span class="pre">.pbtxt</span></code> and should be placed inside the <code class="docutils literal notranslate"><span class="pre">training_demo/annotations</span></code> folder.</p>
</div>
<div class="section" id="create-tensorflow-records">
<h3>Create TensorFlow Records<a class="headerlink" href="#create-tensorflow-records" title="Permalink to this headline">¶</a></h3>
<p>Now that we have generated our annotations and split our dataset into the desired training and
testing subsets, it is time to convert our annotations into the so called <code class="docutils literal notranslate"><span class="pre">TFRecord</span></code> format.</p>
<p>Before we proceed to describe the above steps, let’s create a directory where we can store some
scripts. Under the <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code> folder, create a new folder <code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts</span></code>, which we can
use to store some useful scripts. To make things even tidier, let’s create a new folder
<code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts/preprocessing</span></code>, where we shall store scripts that we can use to preprocess
our training inputs. Below is out <code class="docutils literal notranslate"><span class="pre">TensorFlow</span></code> directory tree structure, up to now:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>TensorFlow/
├─ addons/ <span class="o">(</span>Optional<span class="o">)</span>
│  └─ labelImg/
├─ models/
│  ├─ community/
│  ├─ official/
│  ├─ orbit/
│  ├─ research/
│  └─ ...
├─ scripts/
│  └─ preprocessing/
└─ workspace/
   └─ training_demo/
</pre></div>
</div>
<div class="section" id="convert-xml-to-record">
<h4>Convert <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> to <code class="docutils literal notranslate"><span class="pre">*.record</span></code><a class="headerlink" href="#convert-xml-to-record" title="Permalink to this headline">¶</a></h4>
<p>To do this we can write a simple script that iterates through all <code class="docutils literal notranslate"><span class="pre">*.xml</span></code> files in the <code class="docutils literal notranslate"><span class="pre">training_demo/images/train</span></code> and <code class="docutils literal notranslate"><span class="pre">training_demo/images/test</span></code> folders, and generates a <code class="docutils literal notranslate"><span class="pre">*.record</span></code> file for each of the two.</p>
<p>Here is an example script that allows us to do just that:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot; Sample TensorFlow XML-to-TFRecord converter</span>

<span class="sd">usage: generate_tfrecord.py [-h] [-x XML_DIR] [-l LABELS_PATH] [-o OUTPUT_PATH] [-i IMAGE_DIR] [-c CSV_PATH]</span>

<span class="sd">optional arguments:</span>
<span class="sd">  -h, --help            show this help message and exit</span>
<span class="sd">  -x XML_DIR, --xml_dir XML_DIR</span>
<span class="sd">                        Path to the folder where the input .xml files are stored.</span>
<span class="sd">  -l LABELS_PATH, --labels_path LABELS_PATH</span>
<span class="sd">                        Path to the labels (.pbtxt) file.</span>
<span class="sd">  -o OUTPUT_PATH, --output_path OUTPUT_PATH</span>
<span class="sd">                        Path of output TFRecord (.record) file.</span>
<span class="sd">  -i IMAGE_DIR, --image_dir IMAGE_DIR</span>
<span class="sd">                        Path to the folder where the input image files are stored. Defaults to the same directory as XML_DIR.</span>
<span class="sd">  -c CSV_PATH, --csv_path CSV_PATH</span>
<span class="sd">                        Path of output .csv file. If none provided, then no file will be written.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">xml.etree.ElementTree</span> <span class="k">as</span> <span class="nn">ET</span>
<span class="kn">import</span> <span class="nn">argparse</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;2&#39;</span>    <span class="c1"># Suppress TensorFlow logging (1)</span>
<span class="kn">import</span> <span class="nn">tensorflow.compat.v1</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="k">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">object_detection.utils</span> <span class="k">import</span> <span class="n">dataset_util</span><span class="p">,</span> <span class="n">label_map_util</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>

<span class="c1"># Initiate argument parser</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Sample TensorFlow XML-to-TFRecord converter&quot;</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-x&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;--xml_dir&quot;</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the folder where the input .xml files are stored.&quot;</span><span class="p">,</span>
                    <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-l&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;--labels_path&quot;</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the labels (.pbtxt) file.&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-o&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;--output_path&quot;</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path of output TFRecord (.record) file.&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-i&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;--image_dir&quot;</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the folder where the input image files are stored. &quot;</span>
                         <span class="s2">&quot;Defaults to the same directory as XML_DIR.&quot;</span><span class="p">,</span>
                    <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s2">&quot;-c&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;--csv_path&quot;</span><span class="p">,</span>
                    <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path of output .csv file. If none provided, then no file will be &quot;</span>
                         <span class="s2">&quot;written.&quot;</span><span class="p">,</span>
                    <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">image_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">args</span><span class="o">.</span><span class="n">image_dir</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">xml_dir</span>

<span class="n">label_map</span> <span class="o">=</span> <span class="n">label_map_util</span><span class="o">.</span><span class="n">load_labelmap</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">labels_path</span><span class="p">)</span>
<span class="n">label_map_dict</span> <span class="o">=</span> <span class="n">label_map_util</span><span class="o">.</span><span class="n">get_label_map_dict</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">xml_to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Iterates through all .xml files (generated by labelImg) in a given directory and combines</span>
<span class="sd">    them in a single Pandas dataframe.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    path : str</span>
<span class="sd">        The path containing the .xml files</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Pandas DataFrame</span>
<span class="sd">        The produced dataframe</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">xml_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">xml_file</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;/*.xml&#39;</span><span class="p">):</span>
        <span class="n">tree</span> <span class="o">=</span> <span class="n">ET</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">xml_file</span><span class="p">)</span>
        <span class="n">root</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">getroot</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">member</span> <span class="ow">in</span> <span class="n">root</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">):</span>
            <span class="n">value</span> <span class="o">=</span> <span class="p">(</span><span class="n">root</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;filename&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">root</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">root</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                     <span class="n">member</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">,</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">member</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">member</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">member</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">),</span>
                     <span class="nb">int</span><span class="p">(</span><span class="n">member</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
                     <span class="p">)</span>
            <span class="n">xml_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="n">column_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">,</span> <span class="s1">&#39;width&#39;</span><span class="p">,</span> <span class="s1">&#39;height&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="s1">&#39;xmin&#39;</span><span class="p">,</span> <span class="s1">&#39;ymin&#39;</span><span class="p">,</span> <span class="s1">&#39;xmax&#39;</span><span class="p">,</span> <span class="s1">&#39;ymax&#39;</span><span class="p">]</span>
    <span class="n">xml_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">xml_list</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">column_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">xml_df</span>


<span class="k">def</span> <span class="nf">class_text_to_int</span><span class="p">(</span><span class="n">row_label</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">label_map_dict</span><span class="p">[</span><span class="n">row_label</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">group</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">,</span> <span class="s1">&#39;object&#39;</span><span class="p">])</span>
    <span class="n">gb</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">data</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">gb</span><span class="o">.</span><span class="n">get_group</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">filename</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">gb</span><span class="o">.</span><span class="n">groups</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">gb</span><span class="o">.</span><span class="n">groups</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">create_tf_example</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group</span><span class="o">.</span><span class="n">filename</span><span class="p">)),</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fid</span><span class="p">:</span>
        <span class="n">encoded_jpg</span> <span class="o">=</span> <span class="n">fid</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">encoded_jpg_io</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">encoded_jpg</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">encoded_jpg_io</span><span class="p">)</span>
    <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">size</span>

    <span class="n">filename</span> <span class="o">=</span> <span class="n">group</span><span class="o">.</span><span class="n">filename</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="n">image_format</span> <span class="o">=</span> <span class="sa">b</span><span class="s1">&#39;jpg&#39;</span>
    <span class="n">xmins</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">xmaxs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ymins</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ymaxs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">classes_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">group</span><span class="o">.</span><span class="n">object</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">xmins</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;xmin&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">width</span><span class="p">)</span>
        <span class="n">xmaxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;xmax&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">width</span><span class="p">)</span>
        <span class="n">ymins</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;ymin&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">height</span><span class="p">)</span>
        <span class="n">ymaxs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;ymax&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">height</span><span class="p">)</span>
        <span class="n">classes_text</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">))</span>
        <span class="n">classes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_text_to_int</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]))</span>

    <span class="n">tf_example</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Features</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;image/height&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">int64_feature</span><span class="p">(</span><span class="n">height</span><span class="p">),</span>
        <span class="s1">&#39;image/width&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">int64_feature</span><span class="p">(</span><span class="n">width</span><span class="p">),</span>
        <span class="s1">&#39;image/filename&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">bytes_feature</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span>
        <span class="s1">&#39;image/source_id&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">bytes_feature</span><span class="p">(</span><span class="n">filename</span><span class="p">),</span>
        <span class="s1">&#39;image/encoded&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">bytes_feature</span><span class="p">(</span><span class="n">encoded_jpg</span><span class="p">),</span>
        <span class="s1">&#39;image/format&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">bytes_feature</span><span class="p">(</span><span class="n">image_format</span><span class="p">),</span>
        <span class="s1">&#39;image/object/bbox/xmin&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">float_list_feature</span><span class="p">(</span><span class="n">xmins</span><span class="p">),</span>
        <span class="s1">&#39;image/object/bbox/xmax&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">float_list_feature</span><span class="p">(</span><span class="n">xmaxs</span><span class="p">),</span>
        <span class="s1">&#39;image/object/bbox/ymin&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">float_list_feature</span><span class="p">(</span><span class="n">ymins</span><span class="p">),</span>
        <span class="s1">&#39;image/object/bbox/ymax&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">float_list_feature</span><span class="p">(</span><span class="n">ymaxs</span><span class="p">),</span>
        <span class="s1">&#39;image/object/class/text&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">bytes_list_feature</span><span class="p">(</span><span class="n">classes_text</span><span class="p">),</span>
        <span class="s1">&#39;image/object/class/label&#39;</span><span class="p">:</span> <span class="n">dataset_util</span><span class="o">.</span><span class="n">int64_list_feature</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span>
    <span class="p">}))</span>
    <span class="k">return</span> <span class="n">tf_example</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">_</span><span class="p">):</span>

    <span class="n">writer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">python_io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_path</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">image_dir</span><span class="p">)</span>
    <span class="n">examples</span> <span class="o">=</span> <span class="n">xml_to_csv</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">xml_dir</span><span class="p">)</span>
    <span class="n">grouped</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="s1">&#39;filename&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">grouped</span><span class="p">:</span>
        <span class="n">tf_example</span> <span class="o">=</span> <span class="n">create_tf_example</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tf_example</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Successfully created the TFRecord file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_path</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">csv_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">examples</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">csv_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Successfully created the CSV file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">csv_path</span><span class="p">))</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
</pre></div>
</div>
<ul>
<li><p>Click <a class="reference download internal" download="" href="_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py"><code class="xref download docutils literal notranslate"><span class="pre">here</span></code></a> to download the above script and save it inside <code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts/preprocessing</span></code>.</p></li>
<li><p>Install the <code class="docutils literal notranslate"><span class="pre">pandas</span></code> package:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="n">pandas</span> <span class="c1"># Anaconda</span>
                     <span class="c1"># or</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">pandas</span>   <span class="c1"># pip</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>Finally, <code class="docutils literal notranslate"><span class="pre">cd</span></code> into <code class="docutils literal notranslate"><span class="pre">TensorFlow/scripts/preprocessing</span></code> and run:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create train data:</span>
<span class="n">python</span> <span class="n">generate_tfrecord</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">x</span> <span class="p">[</span><span class="n">PATH_TO_IMAGES_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">train</span> <span class="o">-</span><span class="n">l</span> <span class="p">[</span><span class="n">PATH_TO_ANNOTATIONS_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">label_map</span><span class="o">.</span><span class="n">pbtxt</span> <span class="o">-</span><span class="n">o</span> <span class="p">[</span><span class="n">PATH_TO_ANNOTATIONS_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">record</span>

<span class="c1"># Create test data:</span>
<span class="n">python</span> <span class="n">generate_tfrecord</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">x</span> <span class="p">[</span><span class="n">PATH_TO_IMAGES_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">test</span> <span class="o">-</span><span class="n">l</span> <span class="p">[</span><span class="n">PATH_TO_ANNOTATIONS_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">label_map</span><span class="o">.</span><span class="n">pbtxt</span> <span class="o">-</span><span class="n">o</span> <span class="p">[</span><span class="n">PATH_TO_ANNOTATIONS_FOLDER</span><span class="p">]</span><span class="o">/</span><span class="n">test</span><span class="o">.</span><span class="n">record</span>

<span class="c1"># For example</span>
<span class="c1"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/train -l C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/train.record</span>
<span class="c1"># python generate_tfrecord.py -x C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/images/test -l C:/Users/sglvladi/Documents/Tensorflow2/workspace/training_demo/annotations/label_map.pbtxt -o C:/Users/sglvladi/Documents/Tensorflow/workspace/training_demo/annotations/test.record</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<p>Once the above is done, there should be 2 new files under the <code class="docutils literal notranslate"><span class="pre">training_demo/annotations</span></code> folder, named <code class="docutils literal notranslate"><span class="pre">test.record</span></code> and <code class="docutils literal notranslate"><span class="pre">train.record</span></code>, respectively.</p>
</div>
</div>
</div>
<div class="section" id="configuring-a-training-job">
<span id="config-training-pipeline-sec"></span><h2>Configuring a Training Job<a class="headerlink" href="#configuring-a-training-job" title="Permalink to this headline">¶</a></h2>
<p>For the purposes of this tutorial we will not be creating a training job from scratch, but rather
we will reuse one of the pre-trained models provided by TensorFlow. If you would like to train an
entirely new model, you can have a look at <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md">TensorFlow’s tutorial</a>.</p>
<p>The model we shall be using in our examples is the <a class="reference external" href="http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz">SSD ResNet50 V1 FPN 640x640</a>
model, since it provides a relatively good trade-off between performance and speed. However, there
exist a number of other models you can use, all of which are listed in <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow 2 Detection Model Zoo</a>.</p>
<div class="section" id="download-pre-trained-model">
<h3>Download Pre-Trained Model<a class="headerlink" href="#download-pre-trained-model" title="Permalink to this headline">¶</a></h3>
<p>To begin with, we need to download the latest pre-trained network for the model we wish to use.
This can be done by simply clicking on the name of the desired model in the table found in
<a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow 2 Detection Model Zoo</a>.
Clicking on the name of your model should initiate a download for a <code class="docutils literal notranslate"><span class="pre">*.tar.gz</span></code> file.</p>
<p>Once the <code class="docutils literal notranslate"><span class="pre">*.tar.gz</span></code> file has been downloaded, open it using a decompression program of your
choice (e.g. 7zip, WinZIP, etc.). Next, open the <code class="docutils literal notranslate"><span class="pre">*.tar</span></code> folder that you see when the compressed
folder is opened, and extract its contents inside the folder <code class="docutils literal notranslate"><span class="pre">training_demo/pre-trained-models</span></code>.
Since we downloaded the <a class="reference external" href="http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz">SSD ResNet50 V1 FPN 640x640</a>
model, our <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> directory should now look as follows:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>training_demo/
├─ ...
├─ pre-trained-models/
<span class="p">|</span>  └─ ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/
<span class="p">|</span>     ├─ checkpoint/
│     ├─ saved_model/
<span class="p">|</span>     └─ pipeline.config
└─ ...
</pre></div>
</div>
</div></blockquote>
<p>Note that the above process can be repeated for all other pre-trained models you wish to experiment
with. For example, if you wanted to also configure a training job for the <a class="reference external" href="http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz">EfficientDet D1 640x640</a>
model, you can download the model and after extracting its context the demo directory will be:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>training_demo/
├─ ...
├─ pre-trained-models/
│  ├─ efficientdet_d1_coco17_tpu-32/
│  │  ├─ checkpoint/
│  │  ├─ saved_model/
<span class="p">|</span>  │  └─ pipeline.config
│  └─ ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/
<span class="p">|</span>     ├─ checkpoint/
│     ├─ saved_model/
<span class="p">|</span>     └─ pipeline.config
└─ ...
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="configure-the-training-pipeline">
<h3>Configure the Training Pipeline<a class="headerlink" href="#configure-the-training-pipeline" title="Permalink to this headline">¶</a></h3>
<p>Now that we have downloaded and extracted our pre-trained model, let’s create a directory for our
training job. Under the <code class="docutils literal notranslate"><span class="pre">training_demo/models</span></code> create a new directory named <code class="docutils literal notranslate"><span class="pre">my_ssd_resnet50_v1_fpn</span></code>
and copy the <code class="docutils literal notranslate"><span class="pre">training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config</span></code>
file inside the newly created directory. Our <code class="docutils literal notranslate"><span class="pre">training_demo/models</span></code> directory should now look
like this:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>training_demo/
├─ ...
├─ models/
│  └─ my_ssd_resnet50_v1_fpn/
<span class="p">|</span>     └─ pipeline.config
└─ ...
</pre></div>
</div>
</div></blockquote>
<p>Now, let’s have a look at the changes that we shall need to apply to the <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code> file
(highlighted in yellow):</p>
<div class="highlight-default notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="p">{</span>
  <span class="n">ssd</span> <span class="p">{</span>
<span class="hll">    <span class="n">num_classes</span><span class="p">:</span> <span class="mi">1</span> <span class="c1"># Set this to the number of different label classes</span>
</span>    <span class="n">image_resizer</span> <span class="p">{</span>
      <span class="n">fixed_shape_resizer</span> <span class="p">{</span>
        <span class="n">height</span><span class="p">:</span> <span class="mi">640</span>
        <span class="n">width</span><span class="p">:</span> <span class="mi">640</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">feature_extractor</span> <span class="p">{</span>
      <span class="nb">type</span><span class="p">:</span> <span class="s2">&quot;ssd_resnet50_v1_fpn_keras&quot;</span>
      <span class="n">depth_multiplier</span><span class="p">:</span> <span class="mf">1.0</span>
      <span class="n">min_depth</span><span class="p">:</span> <span class="mi">16</span>
      <span class="n">conv_hyperparams</span> <span class="p">{</span>
        <span class="n">regularizer</span> <span class="p">{</span>
          <span class="n">l2_regularizer</span> <span class="p">{</span>
            <span class="n">weight</span><span class="p">:</span> <span class="mf">0.00039999998989515007</span>
          <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">initializer</span> <span class="p">{</span>
          <span class="n">truncated_normal_initializer</span> <span class="p">{</span>
            <span class="n">mean</span><span class="p">:</span> <span class="mf">0.0</span>
            <span class="n">stddev</span><span class="p">:</span> <span class="mf">0.029999999329447746</span>
          <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">RELU_6</span>
        <span class="n">batch_norm</span> <span class="p">{</span>
          <span class="n">decay</span><span class="p">:</span> <span class="mf">0.996999979019165</span>
          <span class="n">scale</span><span class="p">:</span> <span class="n">true</span>
          <span class="n">epsilon</span><span class="p">:</span> <span class="mf">0.0010000000474974513</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">override_base_feature_extractor_hyperparams</span><span class="p">:</span> <span class="n">true</span>
      <span class="n">fpn</span> <span class="p">{</span>
        <span class="n">min_level</span><span class="p">:</span> <span class="mi">3</span>
        <span class="n">max_level</span><span class="p">:</span> <span class="mi">7</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">box_coder</span> <span class="p">{</span>
      <span class="n">faster_rcnn_box_coder</span> <span class="p">{</span>
        <span class="n">y_scale</span><span class="p">:</span> <span class="mf">10.0</span>
        <span class="n">x_scale</span><span class="p">:</span> <span class="mf">10.0</span>
        <span class="n">height_scale</span><span class="p">:</span> <span class="mf">5.0</span>
        <span class="n">width_scale</span><span class="p">:</span> <span class="mf">5.0</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">matcher</span> <span class="p">{</span>
      <span class="n">argmax_matcher</span> <span class="p">{</span>
        <span class="n">matched_threshold</span><span class="p">:</span> <span class="mf">0.5</span>
        <span class="n">unmatched_threshold</span><span class="p">:</span> <span class="mf">0.5</span>
        <span class="n">ignore_thresholds</span><span class="p">:</span> <span class="n">false</span>
        <span class="n">negatives_lower_than_unmatched</span><span class="p">:</span> <span class="n">true</span>
        <span class="n">force_match_for_each_row</span><span class="p">:</span> <span class="n">true</span>
        <span class="n">use_matmul_gather</span><span class="p">:</span> <span class="n">true</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">similarity_calculator</span> <span class="p">{</span>
      <span class="n">iou_similarity</span> <span class="p">{</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">box_predictor</span> <span class="p">{</span>
      <span class="n">weight_shared_convolutional_box_predictor</span> <span class="p">{</span>
        <span class="n">conv_hyperparams</span> <span class="p">{</span>
          <span class="n">regularizer</span> <span class="p">{</span>
            <span class="n">l2_regularizer</span> <span class="p">{</span>
              <span class="n">weight</span><span class="p">:</span> <span class="mf">0.00039999998989515007</span>
            <span class="p">}</span>
          <span class="p">}</span>
          <span class="n">initializer</span> <span class="p">{</span>
            <span class="n">random_normal_initializer</span> <span class="p">{</span>
              <span class="n">mean</span><span class="p">:</span> <span class="mf">0.0</span>
              <span class="n">stddev</span><span class="p">:</span> <span class="mf">0.009999999776482582</span>
            <span class="p">}</span>
          <span class="p">}</span>
          <span class="n">activation</span><span class="p">:</span> <span class="n">RELU_6</span>
          <span class="n">batch_norm</span> <span class="p">{</span>
            <span class="n">decay</span><span class="p">:</span> <span class="mf">0.996999979019165</span>
            <span class="n">scale</span><span class="p">:</span> <span class="n">true</span>
            <span class="n">epsilon</span><span class="p">:</span> <span class="mf">0.0010000000474974513</span>
          <span class="p">}</span>
        <span class="p">}</span>
        <span class="n">depth</span><span class="p">:</span> <span class="mi">256</span>
        <span class="n">num_layers_before_predictor</span><span class="p">:</span> <span class="mi">4</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="mi">3</span>
        <span class="n">class_prediction_bias_init</span><span class="p">:</span> <span class="o">-</span><span class="mf">4.599999904632568</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">anchor_generator</span> <span class="p">{</span>
      <span class="n">multiscale_anchor_generator</span> <span class="p">{</span>
        <span class="n">min_level</span><span class="p">:</span> <span class="mi">3</span>
        <span class="n">max_level</span><span class="p">:</span> <span class="mi">7</span>
        <span class="n">anchor_scale</span><span class="p">:</span> <span class="mf">4.0</span>
        <span class="n">aspect_ratios</span><span class="p">:</span> <span class="mf">1.0</span>
        <span class="n">aspect_ratios</span><span class="p">:</span> <span class="mf">2.0</span>
        <span class="n">aspect_ratios</span><span class="p">:</span> <span class="mf">0.5</span>
        <span class="n">scales_per_octave</span><span class="p">:</span> <span class="mi">2</span>
      <span class="p">}</span>
    <span class="p">}</span>
    <span class="n">post_processing</span> <span class="p">{</span>
      <span class="n">batch_non_max_suppression</span> <span class="p">{</span>
        <span class="n">score_threshold</span><span class="p">:</span> <span class="mf">9.99999993922529e-09</span>
        <span class="n">iou_threshold</span><span class="p">:</span> <span class="mf">0.6000000238418579</span>
        <span class="n">max_detections_per_class</span><span class="p">:</span> <span class="mi">100</span>
        <span class="n">max_total_detections</span><span class="p">:</span> <span class="mi">100</span>
        <span class="n">use_static_shapes</span><span class="p">:</span> <span class="n">false</span>
      <span class="p">}</span>
      <span class="n">score_converter</span><span class="p">:</span> <span class="n">SIGMOID</span>
    <span class="p">}</span>
    <span class="n">normalize_loss_by_num_matches</span><span class="p">:</span> <span class="n">true</span>
    <span class="n">loss</span> <span class="p">{</span>
      <span class="n">localization_loss</span> <span class="p">{</span>
        <span class="n">weighted_smooth_l1</span> <span class="p">{</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">classification_loss</span> <span class="p">{</span>
        <span class="n">weighted_sigmoid_focal</span> <span class="p">{</span>
          <span class="n">gamma</span><span class="p">:</span> <span class="mf">2.0</span>
          <span class="n">alpha</span><span class="p">:</span> <span class="mf">0.25</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">classification_weight</span><span class="p">:</span> <span class="mf">1.0</span>
      <span class="n">localization_weight</span><span class="p">:</span> <span class="mf">1.0</span>
    <span class="p">}</span>
    <span class="n">encode_background_as_zeros</span><span class="p">:</span> <span class="n">true</span>
    <span class="n">normalize_loc_loss_by_codesize</span><span class="p">:</span> <span class="n">true</span>
    <span class="n">inplace_batchnorm_update</span><span class="p">:</span> <span class="n">true</span>
    <span class="n">freeze_batchnorm</span><span class="p">:</span> <span class="n">false</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">train_config</span> <span class="p">{</span>
<span class="hll">  <span class="n">batch_size</span><span class="p">:</span> <span class="mi">8</span> <span class="c1"># Increase/Decrease this value depending on the available memory (Higher values require more memory and vice-versa)</span>
</span>  <span class="n">data_augmentation_options</span> <span class="p">{</span>
    <span class="n">random_horizontal_flip</span> <span class="p">{</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="n">data_augmentation_options</span> <span class="p">{</span>
    <span class="n">random_crop_image</span> <span class="p">{</span>
      <span class="n">min_object_covered</span><span class="p">:</span> <span class="mf">0.0</span>
      <span class="n">min_aspect_ratio</span><span class="p">:</span> <span class="mf">0.75</span>
      <span class="n">max_aspect_ratio</span><span class="p">:</span> <span class="mf">3.0</span>
      <span class="n">min_area</span><span class="p">:</span> <span class="mf">0.75</span>
      <span class="n">max_area</span><span class="p">:</span> <span class="mf">1.0</span>
      <span class="n">overlap_thresh</span><span class="p">:</span> <span class="mf">0.0</span>
    <span class="p">}</span>
  <span class="p">}</span>
  <span class="n">sync_replicas</span><span class="p">:</span> <span class="n">true</span>
  <span class="n">optimizer</span> <span class="p">{</span>
    <span class="n">momentum_optimizer</span> <span class="p">{</span>
      <span class="n">learning_rate</span> <span class="p">{</span>
        <span class="n">cosine_decay_learning_rate</span> <span class="p">{</span>
          <span class="n">learning_rate_base</span><span class="p">:</span> <span class="mf">0.03999999910593033</span>
          <span class="n">total_steps</span><span class="p">:</span> <span class="mi">25000</span>
          <span class="n">warmup_learning_rate</span><span class="p">:</span> <span class="mf">0.013333000242710114</span>
          <span class="n">warmup_steps</span><span class="p">:</span> <span class="mi">2000</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">momentum_optimizer_value</span><span class="p">:</span> <span class="mf">0.8999999761581421</span>
    <span class="p">}</span>
    <span class="n">use_moving_average</span><span class="p">:</span> <span class="n">false</span>
  <span class="p">}</span>
<span class="hll">  <span class="n">fine_tune_checkpoint</span><span class="p">:</span> <span class="s2">&quot;pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0&quot;</span> <span class="c1"># Path to checkpoint of pre-trained model</span>
</span>  <span class="n">num_steps</span><span class="p">:</span> <span class="mi">25000</span>
  <span class="n">startup_delay_steps</span><span class="p">:</span> <span class="mf">0.0</span>
  <span class="n">replicas_to_aggregate</span><span class="p">:</span> <span class="mi">8</span>
  <span class="n">max_number_of_boxes</span><span class="p">:</span> <span class="mi">100</span>
  <span class="n">unpad_groundtruth_tensors</span><span class="p">:</span> <span class="n">false</span>
<span class="hll">  <span class="n">fine_tune_checkpoint_type</span><span class="p">:</span> <span class="s2">&quot;detection&quot;</span> <span class="c1"># Set this to &quot;detection&quot; since we want to be training the full detection model</span>
</span><span class="hll">  <span class="n">use_bfloat16</span><span class="p">:</span> <span class="n">false</span> <span class="c1"># Set this to false if you are not training on a TPU</span>
</span>  <span class="n">fine_tune_checkpoint_version</span><span class="p">:</span> <span class="n">V2</span>
<span class="p">}</span>
<span class="n">train_input_reader</span> <span class="p">{</span>
<span class="hll">  <span class="n">label_map_path</span><span class="p">:</span> <span class="s2">&quot;annotations/label_map.pbtxt&quot;</span> <span class="c1"># Path to label map file</span>
</span>  <span class="n">tf_record_input_reader</span> <span class="p">{</span>
<span class="hll">    <span class="n">input_path</span><span class="p">:</span> <span class="s2">&quot;annotations/train.record&quot;</span> <span class="c1"># Path to training TFRecord file</span>
</span>  <span class="p">}</span>
<span class="p">}</span>
<span class="n">eval_config</span> <span class="p">{</span>
<span class="hll">  <span class="n">metrics_set</span><span class="p">:</span> <span class="s2">&quot;coco_detection_metrics&quot;</span>
</span><span class="hll">  <span class="n">use_moving_averages</span><span class="p">:</span> <span class="n">false</span>
</span><span class="p">}</span>
<span class="n">eval_input_reader</span> <span class="p">{</span>
<span class="hll">  <span class="n">label_map_path</span><span class="p">:</span> <span class="s2">&quot;annotations/label_map.pbtxt&quot;</span> <span class="c1"># Path to label map file</span>
</span>  <span class="n">shuffle</span><span class="p">:</span> <span class="n">false</span>
  <span class="n">num_epochs</span><span class="p">:</span> <span class="mi">1</span>
  <span class="n">tf_record_input_reader</span> <span class="p">{</span>
<span class="hll">    <span class="n">input_path</span><span class="p">:</span> <span class="s2">&quot;annotations/test.record&quot;</span> <span class="c1"># Path to testing TFRecord</span>
</span>  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</td></tr></table></div>
<p>It is worth noting here that the changes to lines <code class="docutils literal notranslate"><span class="pre">178</span></code> to <code class="docutils literal notranslate"><span class="pre">179</span></code> above are optional. These
should only be used if you installed the COCO evaluation tools, as outlined in the
<a class="reference internal" href="install.html#tf-models-install-coco"><span class="std std-ref">COCO API installation</span></a> section, and you intend to run evaluation (see <a class="reference internal" href="#evaluation-sec"><span class="std std-ref">Evaluating the Model (Optional)</span></a>).</p>
<p>Once the above changes have been applied to our config file, go ahead and save it.</p>
</div>
</div>
<div class="section" id="training-the-model">
<span id="training-sec"></span><h2>Training the Model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">¶</a></h2>
<p>Before we begin training our model, let’s go and copy the <code class="docutils literal notranslate"><span class="pre">TensorFlow/models/research/object_detection/model_main_tf2.py</span></code>
script and paste it straight into our <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder. We will need this script in order
to train our model.</p>
<p>Now, to initiate a new training job, open a new <cite>Terminal</cite>,  <code class="docutils literal notranslate"><span class="pre">cd</span></code> inside the <code class="docutils literal notranslate"><span class="pre">training_demo</span></code>
folder and run the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">model_main_tf2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="n">models</span><span class="o">/</span><span class="n">my_ssd_resnet50_v1_fpn</span> <span class="o">--</span><span class="n">pipeline_config_path</span><span class="o">=</span><span class="n">models</span><span class="o">/</span><span class="n">my_ssd_resnet50_v1_fpn</span><span class="o">/</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span>
</pre></div>
</div>
<p>Once the training process has been initiated, you should see a series of print outs similar to the
one below (plus/minus some warnings):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">gamma</span>
<span class="n">W0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mf">19.105542</span>  <span class="mi">1364</span> <span class="n">util</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">143</span><span class="p">]</span> <span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">gamma</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">beta</span>
<span class="n">W0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mf">19.106541</span>  <span class="mi">1364</span> <span class="n">util</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">143</span><span class="p">]</span> <span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">beta</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">moving_mean</span>
<span class="n">W0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mf">19.107540</span>  <span class="mi">1364</span> <span class="n">util</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">143</span><span class="p">]</span> <span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">moving_mean</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">moving_variance</span>
<span class="n">W0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mf">19.108539</span>  <span class="mi">1364</span> <span class="n">util</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">143</span><span class="p">]</span> <span class="n">Unresolved</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_box_predictor</span><span class="o">.</span><span class="n">_base_tower_layers_for_heads</span><span class="o">.</span><span class="n">class_predictions_with_background</span><span class="o">.</span><span class="mf">4.10</span><span class="o">.</span><span class="n">moving_variance</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">A</span> <span class="n">checkpoint</span> <span class="n">was</span> <span class="n">restored</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="o">.</span><span class="n">restore</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">)</span> <span class="n">but</span> <span class="ow">not</span> <span class="nb">all</span> <span class="n">checkpointed</span> <span class="n">values</span> <span class="n">were</span> <span class="n">used</span><span class="o">.</span> <span class="n">See</span> <span class="n">above</span> <span class="k">for</span> <span class="n">specific</span> <span class="n">issues</span><span class="o">.</span> <span class="n">Use</span> <span class="n">expect_partial</span><span class="p">()</span> <span class="n">on</span> <span class="n">the</span> <span class="n">load</span> <span class="n">status</span> <span class="nb">object</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">expect_partial</span><span class="p">(),</span> <span class="n">to</span> <span class="n">silence</span> <span class="n">these</span> <span class="n">warnings</span><span class="p">,</span> <span class="ow">or</span> <span class="n">use</span> <span class="n">assert_consumed</span><span class="p">()</span> <span class="n">to</span> <span class="n">make</span> <span class="n">the</span> <span class="n">check</span> <span class="n">explicit</span><span class="o">.</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">guide</span><span class="o">/</span><span class="n">checkpoint</span><span class="c1">#loading_mechanics for details.</span>
<span class="n">W0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">24</span><span class="p">:</span><span class="mf">19.108539</span>  <span class="mi">1364</span> <span class="n">util</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">151</span><span class="p">]</span> <span class="n">A</span> <span class="n">checkpoint</span> <span class="n">was</span> <span class="n">restored</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="o">.</span><span class="n">restore</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">)</span> <span class="n">but</span> <span class="ow">not</span> <span class="nb">all</span> <span class="n">checkpointed</span> <span class="n">values</span> <span class="n">were</span> <span class="n">used</span><span class="o">.</span> <span class="n">See</span> <span class="n">above</span> <span class="k">for</span> <span class="n">specific</span> <span class="n">issues</span><span class="o">.</span> <span class="n">Use</span> <span class="n">expect_partial</span><span class="p">()</span> <span class="n">on</span> <span class="n">the</span> <span class="n">load</span> <span class="n">status</span> <span class="nb">object</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">.</span><span class="n">expect_partial</span><span class="p">(),</span> <span class="n">to</span> <span class="n">silence</span> <span class="n">these</span> <span class="n">warnings</span><span class="p">,</span> <span class="ow">or</span> <span class="n">use</span> <span class="n">assert_consumed</span><span class="p">()</span> <span class="n">to</span> <span class="n">make</span> <span class="n">the</span> <span class="n">check</span> <span class="n">explicit</span><span class="o">.</span> <span class="n">See</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">guide</span><span class="o">/</span><span class="n">checkpoint</span><span class="c1">#loading_mechanics for details.</span>
<span class="n">WARNING</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">num_readers</span> <span class="n">has</span> <span class="n">been</span> <span class="n">reduced</span> <span class="n">to</span> <span class="mi">1</span> <span class="n">to</span> <span class="n">match</span> <span class="nb">input</span> <span class="n">file</span> <span class="n">shards</span><span class="o">.</span>
<span class="n">INFO</span><span class="p">:</span><span class="n">tensorflow</span><span class="p">:</span><span class="n">Step</span> <span class="mi">100</span> <span class="n">per</span><span class="o">-</span><span class="n">step</span> <span class="n">time</span> <span class="mf">1.153</span><span class="n">s</span> <span class="n">loss</span><span class="o">=</span><span class="mf">0.761</span>
<span class="n">I0716</span> <span class="mi">05</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mf">55.879558</span>  <span class="mi">1364</span> <span class="n">model_lib_v2</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">632</span><span class="p">]</span> <span class="n">Step</span> <span class="mi">100</span> <span class="n">per</span><span class="o">-</span><span class="n">step</span> <span class="n">time</span> <span class="mf">1.153</span><span class="n">s</span> <span class="n">loss</span><span class="o">=</span><span class="mf">0.761</span>
<span class="o">...</span>
</pre></div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The output will normally look like it has “frozen”, but DO NOT rush to cancel the process. The
training outputs logs only every 100 steps by default, therefore if you wait for a while, you
should see a log for the loss at step 100.</p>
<p>The time you should wait can vary greatly, depending on whether you are using a GPU and the
chosen value for <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> in the config file, so be patient.</p>
</div>
<p>If you ARE observing a similar output to the above, then CONGRATULATIONS, you have successfully
started your first training job. Now you may very well treat yourself to a cold beer, as waiting
on the training to finish is likely to take a while. Following what people have said online, it
seems that it is advisable to allow you model to reach a <code class="docutils literal notranslate"><span class="pre">TotalLoss</span></code> of at least 2 (ideally 1
and lower) if you want to achieve “fair” detection results. Obviously, lower <code class="docutils literal notranslate"><span class="pre">TotalLoss</span></code> is
better, however very low <code class="docutils literal notranslate"><span class="pre">TotalLoss</span></code> should be avoided, as the model may end up overfitting the
dataset, meaning that it will perform poorly when applied to images outside the dataset. To
monitor <code class="docutils literal notranslate"><span class="pre">TotalLoss</span></code>, as well as a number of other metrics, while your model is training, have a
look at <a class="reference internal" href="#tensorboard-sec"><span class="std std-ref">Monitor Training Job Progress using TensorBoard</span></a>.</p>
<p>If you ARE NOT seeing a print-out similar to that shown above, and/or the training job crashes
after a few seconds, then have a look at the issues and proposed solutions, under the
<a class="reference internal" href="issues.html#issues"><span class="std std-ref">Common issues</span></a> section, to see if you can find a solution. Alternatively, you can try the issues
section of the official <a class="reference external" href="https://github.com/tensorflow/models/issues">Tensorflow Models repo</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Training times can be affected by a number of factors such as:</p>
<ul class="simple">
<li><p>The computational power of you hardware (either CPU or GPU): Obviously, the more powerful your PC is, the faster the training process.</p></li>
<li><p>Whether you are using the TensorFlow CPU or GPU variant: In general, even when compared to the best CPUs, almost any GPU graphics card will yield much faster training and detection speeds. As a matter of fact, when I first started I was running TensorFlow on my <cite>Intel i7-5930k</cite> (6/12 cores &#64; 4GHz, 32GB RAM) and was getting step times of around <cite>12 sec/step</cite>, after which I installed TensorFlow GPU and training the very same model -using the same dataset and config files- on a <cite>EVGA GTX-770</cite> (1536 CUDA-cores &#64; 1GHz, 2GB VRAM) I was down to <cite>0.9 sec/step</cite>!!! A 12-fold increase in speed, using a “low/mid-end” graphics card, when compared to a “mid/high-end” CPU.</p></li>
<li><p>The complexity of the objects you are trying to detect: Obviously, if your objective is to track a black ball over a white background, the model will converge to satisfactory levels of detection pretty quickly. If on the other hand, for example, you wish to detect ships in ports, using Pan-Tilt-Zoom cameras, then training will be a much more challenging and time-consuming process, due to the high variability of the shape and size of ships, combined with a highly dynamic background.</p></li>
<li><p>And many, many, many, more….</p></li>
</ul>
</div>
</div>
<div class="section" id="evaluating-the-model-optional">
<span id="evaluation-sec"></span><h2>Evaluating the Model (Optional)<a class="headerlink" href="#evaluating-the-model-optional" title="Permalink to this headline">¶</a></h2>
<p>By default, the training process logs some basic measures of training performance. These seem to
change depending on the installed version of Tensorflow.</p>
<p>As you will have seen in various parts of this tutorial, we have mentioned a few times the
optional utilisation of the COCO evaluation metrics. Also, under section
<span class="xref std std-ref">_image_partitioning_sec</span> we partitioned our dataset in two parts, where one was to be used
for training and the other for evaluation. In this section we will look at how we can use these
metrics, along with the test images, to get a sense of the performance achieved by our model as it
is being trained.</p>
<p>Firstly, let’s start with a brief explanation of what the evaluation process does. While the
training process runs, it will occasionally create checkpoint files inside the
<code class="docutils literal notranslate"><span class="pre">training_demo/training</span></code> folder, which correspond to snapshots of the model at given steps. When
a set of such new checkpoint files is generated, the evaluation process uses these files and
evaluates how well the model performs in detecting objects in the test dataset. The results of
this evaluation are summarised in the form of some metrics, which can be examined over time.</p>
<p>The steps to run the evaluation are outlined below:</p>
<ol class="arabic simple">
<li><p>Firstly we need to download and install the metrics we want to use.</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>For a description of the supported object detection evaluation metrics, see <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/evaluation_protocols.md">here</a>.</p></li>
<li><p>The process of installing the COCO evaluation metrics is described in <a class="reference internal" href="install.html#tf-models-install-coco"><span class="std std-ref">COCO API installation</span></a>.</p></li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><p>Secondly, we must modify the configuration pipeline (<code class="docutils literal notranslate"><span class="pre">*.config</span></code> script).</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>See lines 178 and 181 of the script in <a class="reference internal" href="#config-training-pipeline-sec"><span class="std std-ref">Configuring a Training Job</span></a>.</p></li>
</ul>
</div></blockquote>
<ol class="arabic" start="3">
<li><p>The third step is to actually run the evaluation. To do so, open a new <cite>Terminal</cite>,  <code class="docutils literal notranslate"><span class="pre">cd</span></code> inside the <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder and run the following command:</p>
<blockquote>
<div><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">model_main_tf2</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="n">models</span><span class="o">/</span><span class="n">my_ssd_resnet50_v1_fpn</span> <span class="o">--</span><span class="n">pipeline_config_path</span><span class="o">=</span><span class="n">models</span><span class="o">/</span><span class="n">my_ssd_resnet50_v1_fpn</span><span class="o">/</span><span class="n">pipeline</span><span class="o">.</span><span class="n">config</span> <span class="o">--</span><span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">models</span><span class="o">/</span><span class="n">my_ssd_resnet50_v1_fpn</span>
</pre></div>
</div>
<p>Once the above is run, you should see a checkpoint similar to the one below  (plus/minus some warnings):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>...
WARNING:tensorflow:From C:\Users\sglvladi\Anaconda3\envs\tf2\lib\site-packages\object_detection\inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0716 05:44:10.059399 17144 deprecation.py:317] From C:\Users\sglvladi\Anaconda3\envs\tf2\lib\site-packages\object_detection\inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From C:\Users\sglvladi\Anaconda3\envs\tf2\lib\site-packages\object_detection\inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0716 05:44:12.383937 17144 deprecation.py:317] From C:\Users\sglvladi\Anaconda3\envs\tf2\lib\site-packages\object_detection\inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
INFO:tensorflow:Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn
I0716 05:44:22.779590 17144 checkpoint_utils.py:125] Waiting for new checkpoint at models/my_ssd_resnet50_v1_fpn
INFO:tensorflow:Found new checkpoint at models/my_ssd_resnet50_v1_fpn\ckpt-2
I0716 05:44:22.882485 17144 checkpoint_utils.py:134] Found new checkpoint at models/my_ssd_resnet50_v1_fpn\ckpt-2
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
<p>While the evaluation process is running, it will periodically check (every 300 sec by default) and
use the latest <code class="docutils literal notranslate"><span class="pre">models/my_ssd_resnet50_v1_fpn/ckpt-*</span></code> checkpoint files to evaluate the performance
of the model. The results are stored in the form of tf event files (<code class="docutils literal notranslate"><span class="pre">events.out.tfevents.*</span></code>)
inside <code class="docutils literal notranslate"><span class="pre">models/my_ssd_resnet50_v1_fpn/eval_0</span></code>. These files can then be used to monitor the
computed metrics, using the process described by the next section.</p>
</div>
<div class="section" id="monitor-training-job-progress-using-tensorboard">
<span id="tensorboard-sec"></span><h2>Monitor Training Job Progress using TensorBoard<a class="headerlink" href="#monitor-training-job-progress-using-tensorboard" title="Permalink to this headline">¶</a></h2>
<p>A very nice feature of TensorFlow, is that it allows you to coninuously monitor and visualise a
number of different training/evaluation metrics, while your model is being trained. The specific
tool that allows us to do all that is <a class="reference external" href="https://www.tensorflow.org/tensorboard">Tensorboard</a>.</p>
<p>To start a new TensorBoard server, we follow the following steps:</p>
<ul>
<li><p>Open a new <cite>Anaconda/Command Prompt</cite></p></li>
<li><p>Activate your TensorFlow conda environment (if you have one), e.g.:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>activate tensorflow_gpu
</pre></div>
</div>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">cd</span></code> into the <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder.</p></li>
<li><p>Run the following command:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tensorboard --logdir<span class="o">=</span>models/my_ssd_resnet50_v1_fpn
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
<p>The above command will start a new TensorBoard server, which (by default) listens to port 6006 of
your machine. Assuming that everything went well, you should see a print-out similar to the one
below (plus/minus some warnings):</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>...
TensorBoard <span class="m">2</span>.2.2 at http://localhost:6006/ <span class="o">(</span>Press CTRL+C to quit<span class="o">)</span>
</pre></div>
</div>
</div></blockquote>
<p>Once this is done, go to your browser and type <code class="docutils literal notranslate"><span class="pre">http://localhost:6006/</span></code> in your address bar,
following which you should be presented with a dashboard similar to the one shown below
(maybe less populated if your model has just started training):</p>
<a class="reference internal image-reference" href="_images/TensorBoard.JPG"><img alt="alternate text" class="align-center" src="_images/TensorBoard.JPG" style="width: 90%;" /></a>
</div>
<div class="section" id="exporting-a-trained-inference-graph">
<h2>Exporting a Trained Inference Graph<a class="headerlink" href="#exporting-a-trained-inference-graph" title="Permalink to this headline">¶</a></h2>
<p>Once your training job is complete, you need to extract the newly trained inference graph, which
will be later used to perform the object detection. This can be done as follows:</p>
<ul class="simple">
<li><p>Copy the <code class="docutils literal notranslate"><span class="pre">TensorFlow/models/research/object_detection/exporter_main_v2.py</span></code> script and paste it straight into your <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder.</p></li>
<li><p>Now, open a <cite>Terminal</cite>, <code class="docutils literal notranslate"><span class="pre">cd</span></code> inside your <code class="docutils literal notranslate"><span class="pre">training_demo</span></code> folder, and run the following command:</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python .<span class="se">\e</span>xporter_main_v2.py --input_type image_tensor --pipeline_config_path .<span class="se">\m</span>odels<span class="se">\m</span>y_efficientdet_d1<span class="se">\p</span>ipeline.config --trained_checkpoint_dir .<span class="se">\m</span>odels<span class="se">\m</span>y_efficientdet_d1<span class="se">\ </span>--output_directory .<span class="se">\t</span>rained-inference-graphs<span class="se">\o</span>utput
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You may get the following error when trying to export your model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>
  <span class="n">File</span> <span class="s2">&quot;.\exporter_main_v2.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">126</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
    <span class="n">app</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">main</span><span class="p">)</span>
  <span class="n">File</span> <span class="s2">&quot;C:\Users\sglvladi\Anaconda3\envs</span><span class="se">\t</span><span class="s2">f2\lib\site-packages</span><span class="se">\a</span><span class="s2">bsl</span><span class="se">\a</span><span class="s2">pp.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">299</span><span class="p">,</span> <span class="ow">in</span> <span class="n">run</span>
    <span class="n">_run_main</span><span class="p">(</span><span class="n">main</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
  <span class="o">...</span>
  <span class="n">File</span> <span class="s2">&quot;C:\Users\sglvladi\Anaconda3\envs</span><span class="se">\t</span><span class="s2">f2\lib\site-packages</span><span class="se">\t</span><span class="s2">ensorflow\python\keras\engine</span><span class="se">\b</span><span class="s2">ase_layer.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">1627</span><span class="p">,</span> <span class="ow">in</span> <span class="n">get_losses_for</span>
    <span class="n">reachable</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">get_reachable_from_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
  <span class="n">File</span> <span class="s2">&quot;C:\Users\sglvladi\Anaconda3\envs</span><span class="se">\t</span><span class="s2">f2\lib\site-packages</span><span class="se">\t</span><span class="s2">ensorflow\python\keras\utils</span><span class="se">\t</span><span class="s2">f_utils.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">140</span><span class="p">,</span> <span class="ow">in</span> <span class="n">get_reachable_from_inputs</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Expected Operation, Variable, or Tensor, got &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="ne">TypeError</span><span class="p">:</span> <span class="n">Expected</span> <span class="n">Operation</span><span class="p">,</span> <span class="n">Variable</span><span class="p">,</span> <span class="ow">or</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">got</span> <span class="n">level_5</span>
</pre></div>
</div>
<p>If this happens, have a look at the <a class="reference internal" href="issues.html#export-error"><span class="std std-ref">“TypeError: Expected Operation, Variable, or Tensor, got level_5”</span></a> issue section for a potential solution.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="auto_examples/index.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="install.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Lyudmil Vladimirov

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>